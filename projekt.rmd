---
title: "Izvješće"
subtitle: "Prilagodba modela podatcima i linearna regresija"
author: "Matija Bačić, Marko Lazarić, Roman Yatsukha"
date: "12.05.2019."
output: 
  pdf_document:
    includes:
      in_header: header.tex
---
  
```{r, echo = FALSE}
library(knitr)
library(pander)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

# Zadatak A

## Histogrami podataka

```{r}
dice <- read.delim("dice.dat", header=FALSE)
      
barplot(dice$V2, names.arg = dice$V1)
barplot(dice$V3, names.arg = dice$V1)

```

## Testiranje distribucije podataka, procjena parametra p

Parametar p binomne razdiobe možemo procjeniti koristeći procjenu najveće izglednosti. Kod binomne distribucije parametar p možemo procjeniti kao omjer povoljnih ishoda i svih ishoda.

```{r}

desirable.outcomes <- function(values, categories)
  sum(categories * values)

all.outcomes <- function(values, categories)
  max(categories) * sum(values)

estimate.p <- function(values, categories)
  desirable.outcomes(values, categories) / all.outcomes(values, categories)

p.0 = estimate.p(dice$V2, dice$V1)
p.1 = estimate.p(dice$V3, dice$V1)

goodness_of_fit_binomial_test <- function(frequencies, n, p) {
  print_table <- function(observed, expected, caption = 'TODO fix') {
    panderOptions('table.split.table', Inf)
    
    table.frame = data.frame(t(cbind(observed, expected)), row.names = c('$o_i$', '$e_i$'))
    colnames(table.frame) <- c(as.character(0:(length(observed) - 1)))
    pandoc.table(table.frame, style = 'rmarkdown')
  }
  
  observed = frequencies
  expected = sum(observed) * dbinom(0:n, n, p)
  
  pruned.observed = c()
  pruned.expected = c()
  current.sum.observed = 0
  current.sum.expected = 0
  current.index = 1
  
  print_table(observed, expected)
      
  for (i in 1:length(observed)) { 
    if (current.sum.expected + expected[i] > 5) {
      pruned.expected[current.index] <- current.sum.expected + expected[i]
      pruned.observed[current.index] <- current.sum.observed + observed[i]
      
      current.sum.observed = 0
      current.sum.expected = 0
      
      current.index = current.index + 1
    } 
    else {
      current.sum.observed = current.sum.observed + observed[i]
      current.sum.expected = current.sum.expected + expected[i]
    }
  }
  
  if (current.sum.expected > 0 || current.sum.observed > 0) {
    pruned.expected[current.index - 1] <- pruned.expected[current.index - 1] + current.sum.expected
    pruned.observed[current.index - 1] <- pruned.observed[current.index - 1] + current.sum.observed
  }
  
  print_table(pruned.observed, pruned.expected)
  
  X2 = sum((pruned.observed - pruned.expected)^2 / pruned.expected)
  p = pchisq(X2, df=length(pruned.observed) - 1, lower.tail = FALSE)
  
  pandoc.p(sprintf(fmt = "$$ x = \\sum\\limits^k_{i=0} \\frac{(o_i - e_i)^2}{e_i} = %.4f $$", X2))
  pandoc.p(sprintf(fmt = "$$ p = P(X \\ge x) = %.4f $$", p))
}
```

Procjena parametra p za prvi uzorak jest `r sprintf('%.4f', p.0)`, dok je za drugi uzorak `r sprintf('%.4f', p.1)`.
\pagebreak

### Testiranje prvog uzorka s distribucijom $B(12, 1/3)$

```{r results='asis'}
goodness_of_fit_binomial_test(dice$V2, 12, 1/3)
```
\pagebreak

### Testiranje prvog uzorka s distribucijom $B(12, `r sprintf('%.4f', p.0)`)$

```{r results='asis'}
goodness_of_fit_binomial_test(dice$V2, 12, p.0)
```
\pagebreak

### Testiranje drugog uzorka s distribucijom $B(12, 1/3)$

```{r results='asis'}
goodness_of_fit_binomial_test(dice$V3, 12, 1/3)
```
\pagebreak

### Testiranje drugog uzorka s distribucijom $B(12, `r sprintf('%.4f', p.1)`)$

```{r results='asis'}
goodness_of_fit_binomial_test(dice$V3, 12, p.1)
```
\pagebreak

## Usporedba histograma podataka s binomnim razdiobama

```{r}
barplot(dbinom(0:12, 12, 1 / 3), names.arg = 0:12, 
        main = "Binomna razdioba - B(12, 1 / 3)")
barplot(dbinom(0:12, 12, p.0), names.arg = 0:12, 
        main = sprintf(fmt = 'Binomna razdioba - B(12, %.4f)', p.0))
barplot(dbinom(0:12, 12, p.1), names.arg = 0:12, 
        main = sprintf(fmt = 'Binomna razdioba - B(12, %.4f)', p.1))
```

### Razlike

Binomne vjerojatnosti su pomnožene s ukupnim brojem ishoda te su od toga oduzete vrijednosti uzorka.

```{r}
barplot(sum(dice$V2) * dbinom(0:12, 12, 1 / 3) - dice$V2, names.arg = 0:12, 
        main = 'Razlika drugog uzorka i B(12, 1 / 3)')
barplot(sum(dice$V2) * dbinom(0:12, 12, p.0) - dice$V2, names.arg = 0:12, 
        main = sprintf(fmt = 'Razlika prvog uzorka i B(12, %.4f)', p.0))

barplot(sum(dice$V3) * dbinom(0:12, 12, 1 / 3) - dice$V3, names.arg = 0:12, 
        main = 'Razlika drugog uzorka i B(12, 1 / 3)')
barplot(sum(dice$V3) * dbinom(0:12, 12, p.1) - dice$V3, names.arg = 0:12, 
        main = sprintf(fmt = 'Razlika drugog uzorka i B(12, %.4f)', p.1))
```

## Određivanje intervala pouzdanosti za parametar p

Koristeći Clopper-Pearson intervalnu procjenu možemo procjeniti interval pouzdanosti parametra p. 

```{r}

confidence.interval <- function(values, categories, interval) {
  alpha.half <- (1 - interval) / 2
  
  x <- desirable.outcomes(values, categories)
  n <- all.outcomes(values, categories)
  
  c(qbeta(alpha.half, x, n - x + 1), qbeta(1 - alpha.half, x + 1, n - x))
}

interval = 0.95

cp.0 = confidence.interval(dice$V2, dice$V1, interval)
cp.1 = confidence.interval(dice$V3, dice$V1, interval)

```

`r interval * 100`% interval pouzdanosti za prvi uzorak jest: [`r sprintf('%.4f, %.4f', cp.0[1], cp.0[2])`], dok je za drugi uzorak: [`r sprintf('%.4f, %.4f', cp.1[1], cp.1[2])`].

# Zadatak B

```{r}
library(ggplot2)
forbes <- read.table("forbes.dat", quote="\"", comment.char="")
hooker <- read.table("hooker.dat", quote="\"", comment.char="")
fh_concat <- rbind(forbes, hooker)

names(fh_concat)[names(fh_concat) == "V1"] <- "Vreliste"
names(fh_concat)[names(fh_concat) == "V2"] <- "Tlak"

plot(fh_concat$Vreliste, fh_concat$Tlak)

# LINEARNI MODEL

linear_model <- lm(Vreliste ~ Tlak, data = fh_concat)
linear_model

plot(fh_concat$Tlak, fh_concat$Vreliste, pch=16, xlab = "Tlak", ylab = "Vreliste", cex.lab = 1.3, col = "red" ) + abline(linear_model, col = "blue")

# Ili ggplot:

ggplot(fh_concat, aes(Tlak, Vreliste)) +
  geom_point() +
  stat_smooth(method = lm, size = 1, se = FALSE)

# KVADRATICNI MODEL

Tlak2 <- fh_concat$Tlak^2
quadratic_model <-lm(Vreliste ~ Tlak + Tlak2, data = fh_concat)
quadratic_model

timevalues <- seq(0, 30, 0.1)
predictedcounts <- predict(quadratic_model,list(Tlak=timevalues, Tlak2=timevalues^2))

plot(fh_concat$Tlak, fh_concat$Vreliste, pch=16, xlab = "Tlak", ylab = "Vreliste", cex.lab = 1.3, col = "blue") + lines(timevalues, predictedcounts, col = "darkgreen", lwd = 3)

# Ili ggplot:
ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), size = 1, se = FALSE)

# REZIDUALI
fh_concat$predictedLinear = predict(linear_model)
fh_concat$residualsLinear = residuals(linear_model)
fh_concat$stdResidualsLinear = rstandard(linear_model)
fh_concat$predictedQuadratic = predict(quadratic_model)
fh_concat$residualsQuadratic = residuals(quadratic_model)
fh_concat$stdResidualsQuadratic = rstandard(quadratic_model)

# Linear residuals
ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = Tlak, yend = predictedLinear), alpha = .2) +      # draw line from point to line
  geom_point(aes(color = abs(residualsLinear), size = abs(residualsLinear))) +  # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # Size legend removed
  geom_point(aes(y = predictedLinear), shape = 1) +
  theme_bw()

# Std linear residuals
ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = Tlak, yend = predictedLinear), alpha = .2) +      # draw line from point to line
  geom_point(aes(color = abs(stdResidualsLinear), size = abs(stdResidualsLinear))) +  # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # Size legend removed
  geom_point(aes(y = predictedLinear), shape = 1) +
  theme_bw()

# Quadratic residuals
ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = Tlak, yend = predictedQuadratic), alpha = .2) +      # draw line from point to line
  geom_point(aes(color = abs(residualsQuadratic), size = abs(residualsQuadratic))) +  # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # Size legend removed
  geom_point(aes(y = predictedQuadratic), shape = 1) +
  theme_bw()

# Std linear residuals
ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +     # regression line  
  geom_segment(aes(xend = Tlak, yend = predictedQuadratic), alpha = .2) +      # draw line from point to line
  geom_point(aes(color = abs(stdResidualsQuadratic), size = abs(stdResidualsQuadratic))) +  # size of the points
  scale_color_continuous(low = "green", high = "red") +             # colour of the points mapped to residual size - green smaller, red larger
  guides(color = FALSE, size = FALSE) +                             # Size legend removed
  geom_point(aes(y = predictedQuadratic), shape = 1) +
  theme_bw()

# Checking normality lin residuals (normal prob plot)
qqnorm(fh_concat$stdResidualsLinear, xlab="Standardizirani reziduali", ylab="Z-vrijednost", main="Reziduali linearne regresije (normalni vjerojatnosni graf)")

# Checking normality quad residuals (normal prob plot)
qqnorm(fh_concat$stdResidualsQuadratic, xlab="Standardizirani reziduali", ylab="Z-vrijednost", main="Reziduali kvadratne regresije (normalni vjerojatnosni graf)")

# Checking normality lin residuals (Kolmogorov-Smirnov test)
ks.test(fh_concat$stdResidualsLinear, "pnorm", mean=mean(fh_concat$stdResidualsLinear), sd=sd(fh_concat$stdResidualsLinear))

# Checking normality quad residuals (Kolmogorov-Smirnov test)
ks.test(fh_concat$stdResidualsQuadratic, "pnorm", mean=mean(fh_concat$stdResidualsQuadratic), sd=sd(fh_concat$stdResidualsQuadratic))

```