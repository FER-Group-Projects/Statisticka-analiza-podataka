---
title: "Prilagodba modela podatcima i linearna regresija"
subtitle: "Izvješće"
author: "Matija Bačić, Marko Lazarić, Roman Yatsukha"
date: "29.05.2019."
output: 
  pdf_document:
    includes:
      in_header: header.tex 
---
  
```{r, echo = FALSE}
library(knitr)
library(pander)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

\thispagestyle{empty}
\clearpage
\tableofcontents
\thispagestyle{empty}
\clearpage

# Zadatak A

## Histogrami podataka

```{r}
dice <- read.delim("dice.dat", header=FALSE)
      
barplot(dice$V2 / sum(dice$V2),
        main = 'Frekvencije kategorija, I. uzorak',
        names.arg = dice$V1)

barplot(dice$V3 / sum(dice$V3),
        main = 'Frekvencije kategorija, II. uzorak',
        names.arg = dice$V1)

```

## Testiranje distribucije podataka, procjena parametra p

Parametar p binomne razdiobe možemo procjeniti koristeći procjenu najveće izglednosti. Kod binomne distribucije parametar p možemo procjeniti kao omjer povoljnih ishoda i svih ishoda. `binom.test` također nudi procjenu parametra p binomne razdiobe.

```{r}

desirable.outcomes <- function(values, categories)
  sum(categories * values)

all.outcomes <- function(values, categories)
  max(categories) * sum(values)

estimate.p <- function(values, categories)
  desirable.outcomes(values, categories) / all.outcomes(values, categories)

# p.0 = estimate.p(dice$V2, dice$V1)
# p.1 = estimate.p(dice$V3, dice$V1)

p.0 = unname(binom.test(x = desirable.outcomes(dice$V2, dice$V1),
                        n = all.outcomes(dice$V2, dice$V1))$estimate)

p.1 = unname(binom.test(x = desirable.outcomes(dice$V3, dice$V1),
                        n = all.outcomes(dice$V3, dice$V1))$estimate)
```

Procjena parametra p za prvi uzorak jest `r sprintf('%.4f', p.0)`, dok je za drugi uzorak `r sprintf('%.4f', p.1)`.
\pagebreak

```{r results='asis'}
goodness_of_fit_binomial_test <- function(frequencies, n, p, p.estimated = FALSE) {
  print_table <- function(observed, expected, caption = 'TODO fix') {
    panderOptions('table.split.table', Inf)
    
    table.frame = data.frame(t(cbind(observed, expected)), row.names = c('$o_i$', '$e_i$'))
    colnames(table.frame) <- c(as.character(0:(length(observed) - 1)))
    pandoc.table(table.frame, style = 'rmarkdown', caption = caption)
  }
  
  observed = frequencies
  expected = round(sum(observed) * dbinom(0:n, n, p))
  
  pruned.observed = c()
  pruned.expected = c()
  current.sum.observed = 0
  current.sum.expected = 0
  current.index = 1
  
  print_table(observed, expected, 'Opažene i očekivane frekvencije.')
      
  for (i in 1:length(observed)) { 
    if (current.sum.expected + expected[i] >= 5) {
      pruned.expected[current.index] <- current.sum.expected + expected[i]
      pruned.observed[current.index] <- current.sum.observed + observed[i]
      
      current.sum.observed = 0
      current.sum.expected = 0
      
      current.index = current.index + 1
    } 
    else {
      current.sum.observed = current.sum.observed + observed[i]
      current.sum.expected = current.sum.expected + expected[i]
    }
  }
  
  if (current.sum.expected > 0 || current.sum.observed > 0) {
    pruned.expected[current.index - 1] <- 
      pruned.expected[current.index - 1] + current.sum.expected
    pruned.observed[current.index - 1] <- 
      pruned.observed[current.index - 1] + current.sum.observed
  }
  
  print_table(pruned.observed, pruned.expected, 
              caption = 'Opažene i očekivane frekvencije nakon što su razredi s manje od 5 opažanja spojeni.')
  
  X2 = sum((pruned.observed - pruned.expected)^2 / pruned.expected)
  #p = pchisq(X2, df = length(pruned.observed) - (if (p.estimated) 2 else 1), 
  #           lower.tail = FALSE)
  p = chisq.test(x = pruned.observed, p = pruned.expected / sum(pruned.expected))$p.value
  
  pandoc.p(sprintf(
    fmt = "$$ x = \\sum\\limits^k_{i=0} \\frac{(o_i - e_i)^2}{e_i} = %.4f $$", X2))
  pandoc.p(sprintf(fmt = "$$ p = P(X \\ge x) = %.4f $$", p))
}
```
\clearpage

### Testiranje prvog uzorka s distribucijom $B(12, 1/3)$
$$H_0: o_i = e_i,\ \ i = \{1, ..., k\}$$
$$H_1: o_i \ne e_i,\text{ za neki } i$$
```{r results='asis'}
goodness_of_fit_binomial_test(dice$V2, 12, 1/3)
```

Uz nivo značajnosti 5%, ne možemo odbaciti $H_0$ jer je $p > 0.05$.
\pagebreak

### Testiranje prvog uzorka s distribucijom $B(12, `r sprintf('%.4f', p.0)`)$
$$H_0: o_i = e_i,\ \ i = \{1, ..., k\}$$
$$H_1: o_i \ne e_i,\text{ za neki } i$$
```{r results='asis'}
goodness_of_fit_binomial_test(dice$V2, 12, p.0, p.estimated = TRUE)
```

Uz nivo značajnosti 5%, ne možemo odbaciti $H_0$ jer je $p > 0.05$.
\pagebreak

### Testiranje drugog uzorka s distribucijom $B(12, 1/3)$
$$H_0: o_i = e_i,\ \ i = \{1, ..., k\}$$
$$H_1: o_i \ne e_i,\text{ za neki } i$$
```{r results='asis'}
goodness_of_fit_binomial_test(dice$V3, 12, 1/3)
```

Uz nivo značajnosti 5%, odbacujemo $H_0$ u korist $H_1$ jer je $p \leq 0.05$.
\pagebreak

### Testiranje drugog uzorka s distribucijom $B(12, `r sprintf('%.4f', p.1)`)$
$$H_0: o_i = e_i,\ \ i = \{1, ..., k\}$$
$$H_1: o_i \ne e_i,\text{ za neki } i$$
```{r results='asis'}
goodness_of_fit_binomial_test(dice$V3, 12, p.1, p.estimated = TRUE)
```

Uz nivo značajnosti 5%, ne možemo odbaciti $H_0$ jer je $p > 0.05$.
\pagebreak

## Usporedba histograma podataka s binomnim razdiobama

```{r}

legend.scale = 0.7

barplot(rbind(dice$V2 / sum(dice$V2), dbinom(0:12, 12, 1 / 3), dbinom(0:12, 12, p.0)),
        legend.text = c('Frekvencije pojavljivanja kategorija I. uzorka', 
                        'Distribucija B(12, 1 / 3)',
                        sprintf('Distribucija B(12, %.4f)', p.0)),
        args.legend = list('cex' = legend.scale),
        beside = TRUE,
        names.arg = dice$V1)

barplot(rbind(dice$V3 / sum(dice$V3), dbinom(0:12, 12, 1 / 3), dbinom(0:12, 12, p.1)),
        legend.text = c('Frekvencije pojavljivanja kategorija II. uzorka', 
                        'Distribucija B(12, 1 / 3)',
                        sprintf('Distribucija B(12, %.4f)', p.1)),
        args.legend = list('cex' = legend.scale),
        beside = TRUE,
        names.arg = dice$V1)
```

### Razlike

Binomne vjerojatnosti su pomnožene s ukupnim brojem ishoda te su od toga oduzete vrijednosti uzorka. Nakon toga su razlike skalirane što daje relativnu frekvenciju.

```{r}
barplot(rbind(dbinom(0:12, 12, 1 / 3) - dice$V2 / sum(dice$V2), 
              dbinom(0:12, 12, p.0) - dice$V2 / sum(dice$V2)), 
        names.arg = dice$V1, 
        beside = TRUE,
        legend = c('Razlika I. uzorka i B(12, 1 / 3)', 
                   sprintf('Razlika I. uzorka i B(12, %.4f)', p.0)))

barplot(rbind(dbinom(0:12, 12, 1 / 3) - dice$V3 / sum(dice$V3), 
              dbinom(0:12, 12, p.1) - dice$V3 / sum(dice$V3)), 
        names.arg = dice$V1, 
        beside = TRUE,
        legend = c('Razlika II. uzorka i B(12, 1 / 3)', 
                   sprintf('Razlika II. uzorka i B(12, %.4f)', p.1)))
```

## Određivanje intervala pouzdanosti za parametar p

Koristeći Clopper-Pearson intervalnu procjenu možemo procjeniti interval pouzdanosti parametra p. `binom.test` služi kao provjera intervala pouzdanosti jer koristi istu egzaktnu metodu.

```{r}

confidence.interval <- function(values, categories, interval) {
  alpha.half <- (1 - interval) / 2
  
  x <- desirable.outcomes(values, categories)
  n <- all.outcomes(values, categories)
  
  c(qbeta(alpha.half, x, n - x + 1), qbeta(1 - alpha.half, x + 1, n - x))
}

interval = 0.95

# cp.0 = confidence.interval(dice$V2, dice$V1, interval)
# cp.1 = confidence.interval(dice$V3, dice$V1, interval)

cp.0 = binom.test(x = desirable.outcomes(dice$V2, dice$V1),
                  n = all.outcomes(dice$V2, dice$V1),
                  conf.level = interval)$conf.int

cp.1 = binom.test(x = desirable.outcomes(dice$V3, dice$V1),
                  n = all.outcomes(dice$V3, dice$V1),
                  conf.level =  interval)$conf.int

```

`r interval * 100`% interval pouzdanosti za prvi uzorak jest: [`r sprintf('%.4f, %.4f', cp.0[1], cp.0[2])`], dok je za drugi uzorak: [`r sprintf('%.4f, %.4f', cp.1[1], cp.1[2])`].

```{r}
htest.p.0 = binom.test(x = desirable.outcomes(dice$V2, dice$V1), 
                       n = all.outcomes(dice$V2, dice$V1), 
                       p = 1 / 3, alternative = 'two.sided')$p.value

htest.p.1 = binom.test(x = desirable.outcomes(dice$V3, dice$V1), 
                       n = all.outcomes(dice$V3, dice$V1), 
                       p = 1 / 3, alternative = 'two.sided')$p.value

```

## Testiranje hipoteze

$$H_0: p = \frac{1}{3}$$
$$H_1: p \ne \frac{1}{3}$$

Koristeći ugrađenu `binom.test` funkciju možemo provesti test osnovne hipoteze $H_0$ u odnosu na alternativu $H_1$.
Za prvi uzorak p-vrijednost testa jest `r sprintf("%.4f", htest.p.0)` što je ispod nivoa značajnosti. Dakle odbacujemo $H_0$ u korist $H_1$ uz nivo značajnosti 5%.
Kod drugog uzorka p-vrijednost testa je približno 0, stoga isto kao i za prvi uzorak odbacujemo $H_0$ uz nivo značajnosti 5%.

Iste zaključke možemo povući i iz 95% intervala pouzdanosti (prethodna stranica). Vidimo da ni za jedan uzorak $\frac{1}{3}$ ne ulazi u interval. Dakle $\frac{1}{3} \notin [0.3335, 0.3399]$ za prvi uzorak, odnosno $\frac{1}{3} \notin [0.3360, 0.3394]$ za drugi. Na osnovu toga možemo doći do istog zaključka: odbacujemo $H_0$ u korist $H_1$ uz nivo značajnosti 5%.

\clearpage
# Zadatak B

```{r, echo = FALSE}
library(ggplot2)
forbes <- read.table("forbes.dat", quote="\"", comment.char="")
hooker <- read.table("hooker.dat", quote="\"", comment.char="")
fh_concat <- rbind(forbes, hooker)

names(fh_concat)[names(fh_concat) == "V1"] <- "Vreliste"
names(fh_concat)[names(fh_concat) == "V2"] <- "Tlak"
```
```{r}
plot(fh_concat$Vreliste, fh_concat$Tlak)
```

Prikazom podataka, vidimo da graf sugerira linearnu vezu među podacima.

## Linearni model:
.

```{r}
linear_model <- lm(Vreliste ~ Tlak, data = fh_concat)
linear_model
ggplot(fh_concat, aes(Tlak, Vreliste)) +
  geom_point() +
  stat_smooth(method = lm, size = 1, se = FALSE)
```

## Kvadratični model:
.

```{r}
Tlak2 <- fh_concat$Tlak^2
quadratic_model <-lm(Vreliste ~ Tlak + Tlak2, data = fh_concat)
quadratic_model

ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), size = 1, se = FALSE)
```

## Reziduali pojedinih modela:
.

```{r}
fh_concat$predictedLinear = predict(linear_model)
fh_concat$residualsLinear = residuals(linear_model)
fh_concat$stdResidualsLinear = rstandard(linear_model)
fh_concat$predictedQuadratic = predict(quadratic_model)
fh_concat$residualsQuadratic = residuals(quadratic_model)
fh_concat$stdResidualsQuadratic = rstandard(quadratic_model)
x.axis = seq(from = 0, to = nrow(fh_concat) - 1, by = 1)
```

## Prikaz reziduala linearnog modela
.

```{r}
ggplot(data=fh_concat, mapping=aes(x = x.axis, y = residualsLinear)) + 
  geom_point()
```

## Prikaz standardnih reziduala linearnog modela
.

```{r}
ggplot(data=fh_concat, mapping=aes(x = x.axis, y = stdResidualsLinear)) + 
  geom_point()
```

## Prikaz reziduala kvadratičnog modela
.

```{r}
ggplot(data=fh_concat, mapping=aes(x = x.axis, y = residualsQuadratic)) + 
  geom_point()
```

## Prikaz standardnih reziduala kvadratičnog modela
.

```{r}
ggplot(data=fh_concat, mapping=aes(x = x.axis, y = stdResidualsQuadratic)) + 
  geom_point()
```

## Provjera normalnosti reziduala linearnog modela (normalni vjerojatnosni graf)
.

```{r}
qqnorm(fh_concat$stdResidualsLinear, xlab="Standardizirani reziduali", ylab="Z-vrijednost",
       main="Reziduali linearne regresije (normalni vjerojatnosni graf)"); qqline(fh_concat$stdResidualsLinear)
```

## Provjera normalnosti reziduala kvadratičnog modela (normalni vjerojatnosni graf)
.

```{r}
qqnorm(fh_concat$stdResidualsQuadratic, xlab="Standardizirani reziduali", ylab="Z-vrijednost", 
       main="Reziduali kvadratne regresije (normalni vjerojatnosni graf)"); qqline(fh_concat$stdResidualsQuadratic)
```

## Provjera normalnosti reziduala linearnog modela (Kolmogorov-Smirnovljev test)
.

```{r}
ks.test(fh_concat$stdResidualsLinear, "pnorm", mean=mean(fh_concat$stdResidualsLinear), 
        sd=sd(fh_concat$stdResidualsLinear))
```

## Provjera normalnosti reziduala kvadratičnog modela (Kolmogorov-Smirnovljev test)
.

```{r}
ks.test(fh_concat$stdResidualsQuadratic, "pnorm", mean=mean(fh_concat$stdResidualsQuadratic), 
        sd=sd(fh_concat$stdResidualsQuadratic))
```
Gledajući i po normalnom vjerojatnosnom grafu i po Kolmogorov-Smirnovljevom testu, reziduali kvadratičnog modela ipak malo bolje odgovaraju jediničnoj normalnoj distribuciji. Iako, i jedni i drugi reziduali imaju dosta visoku p vrijednost.

## R^2 statistika
```{r}
summary(linear_model)$r.squared
summary(quadratic_model)$r.squared
```
U ovom koraku, zaključili bismo da kvadratični model bolje opisuje zadani uzorak. Budući da smo u prošlom koraku vidjeli da su reziduali tog modela bliži jediničnoj normalnoj razdiobi, odabrali bismo upravo kvadratični model. Ipak, pogledat ćemo dodatne informacije koje nam pruža ANOVA.

## Anova test prihvatljivosti modela

$$H_0: \text{linearni model je dostatan}$$
$$H_1: \text{linearni model nije dostatan}$$


```{r}
anova(linear_model, quadratic_model)
```
U ovom koraku, dobivamo više informacija. Uz nivo značajnosti 0.05 i uzimajući u obzir p < 2.2e-16, možemo zaključiti da dobivamo statistički značajan napredak koristeći kvadratični u odnosnu na linearni model.

## 95% interval povjerenja za parametre kvadratičnog modela:
.

```{r}
summary(quadratic_model)
confint(quadratic_model, 'Tlak', level=0.95)
confint(quadratic_model, 'Tlak2', level=0.95)
confint(quadratic_model, '(Intercept)', level=0.95)
```

## Granice 95% intervala pouzdanosti za srednju vrijednost od Y (uz dano x)
.

```{r}
confident <- data.frame(Tlak = fh_concat$Tlak, Vreliste = 
                          predict(quadratic_model, fh_concat, interval = 'confidence', 
                                  level = 0.95))

ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_point() +
  geom_smooth(data = confident, aes(x = Tlak, y = Vreliste.lwr), color = 'red') + 
  geom_smooth(data = confident, aes(x = Tlak, y = Vreliste.upr), color = 'blue')
```

## Granice 95% intervala pouzdanosti za Y (uz dano x)
.

```{r}
predicted <- data.frame(Tlak = fh_concat$Tlak, Vreliste = 
                          predict(quadratic_model, fh_concat, interval = 'prediction', 
                                  level = 0.95))

ggplot(fh_concat, aes(x = Tlak, y = Vreliste)) +
  geom_point() +
  geom_smooth(data = predicted, aes(x = Tlak, y = Vreliste.lwr), color = 'red') + 
  geom_smooth(data = predicted, aes(x = Tlak, y = Vreliste.upr), color = 'blue')
```